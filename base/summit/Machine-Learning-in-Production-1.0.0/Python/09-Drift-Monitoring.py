# Databricks notebook source
# MAGIC 
# MAGIC %md-sandbox
# MAGIC 
# MAGIC <div style="text-align: center; line-height: 0; padding-top: 9px;">
# MAGIC   <img src="https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png" alt="Databricks Learning" style="width: 600px; height: 163px">
# MAGIC </div>

# COMMAND ----------

# MAGIC %md
# MAGIC # Drift Monitoring
# MAGIC 
# MAGIC Monitoring models over time entails safeguarding against drift in model performance.  In this lesson, you explore solutions to drift and implement both a basic and dynamic monitoring solution.
# MAGIC 
# MAGIC ## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) In this lesson you:<br>
# MAGIC  - Develop a model monitoring strategy for data drift and model drift
# MAGIC  - Create non-adaptive solutions that peridocially retrain a model
# MAGIC  - Create an adaptive solution that detects and resolves drift

# COMMAND ----------

# MAGIC %md-sandbox
# MAGIC ### Drift
# MAGIC 
# MAGIC The majority of machine learning solutions assume that data is generated according to a stationary probability distribution.  Most datasets involving human activity evolve over time either with known seasonality or with unpredictable elements.  A **context** is the a set of samples from a distribution that are generated by a stationary function.  When this context changes, we can observe a change in the probability distribution.  Monitoring for drift involves monitoring for this change of context, normally by an increase in the error rate.
# MAGIC 
# MAGIC There are two basic categories of solutions.  The first adapts the learner regardless of whether drift has occurred.  This solution would include some notion of memory, whether that's filtering for a certain time window (e.g. all data from the past week) or using weighted examples (e.g. this month's data is weighted twice as important as last month's).  The main challenge with this option is choosing the best window or filtering method.  Without the ability to actively detect drift, it somewhat arbitrarily selects that threshold.
# MAGIC 
# MAGIC The second solution adapts the learner when it detects drift.  An adaptive solution is ideal since it can detect the optimal time for retraining and will make more data available to the learner, improving model performance.
# MAGIC 
# MAGIC <div><img src="https://files.training.databricks.com/images/eLearning/ML-Part-4/drift.png" style="height: 250px; margin: 20px"/></div>
# MAGIC 
# MAGIC This is an example of an adaptive learner.  It monitors incoming data coming incrementally or in new batches for an increase in error.  Once that error reaches a certain threshold, a warning is issued.  Once it reaches a second threshold, the data is said to be in a new context, triggering a retraining of the model on the data between the first and second thresholds.  The thresholds in this example are set using the 95% and 99% confidence intervals.

# COMMAND ----------

# MAGIC %md
# MAGIC Run the following cell to set up our environment.

# COMMAND ----------

# MAGIC %run "./Includes/Classroom-Setup"

# COMMAND ----------

# MAGIC %md
# MAGIC ### Basic Retraining Solution
# MAGIC 
# MAGIC Basic solutions to the issue of drift can include the following:<br><br>
# MAGIC 
# MAGIC  - Retrain the model periodically on all new and historical data
# MAGIC  - Retrain the model on a known window of data (e.g. the last week of data)
# MAGIC  - Retrain the model while weighing more recent data more strongly.
# MAGIC 
# MAGIC To illustrate model retraining, look at code that changes over time to get a sense for how it affects model error.

# COMMAND ----------

# MAGIC %md
# MAGIC Set up a series of predictions draw from 3 different distributions.

# COMMAND ----------

import numpy as np
import pandas as pd

np.random.seed(42)

distribution1 = np.stack([np.random.normal(loc=0, scale=1, size=1000), np.random.random(1000), np.ones(1000)*1]).T
distribution2 = np.stack([np.random.normal(loc=2, scale=1.5, size=1000), np.random.random(1000), np.ones(1000)*2]).T
distribution3 = np.stack([np.random.normal(loc=5, scale=1, size=1000), np.random.random(1000), np.ones(1000)*3]).T

df = pd.DataFrame(np.vstack([distribution1, distribution2, distribution3]), columns=["y", "random-x", "distribution"])
df["time"] = df.index

df

# COMMAND ----------

# MAGIC %md
# MAGIC Visualize the changing distribution over time.

# COMMAND ----------

import matplotlib.pyplot as plt

fig, ax = plt.subplots()

ax.scatter(df['time'], df['y'], c=df['distribution'], alpha=.2)
ax.set_title("Changing Distribution over Time")
ax.set_xlabel("Time")
ax.set_ylabel("Value")

display(fig)

# COMMAND ----------

# MAGIC %md
# MAGIC We can see that the average and spread of the data changes over time across our three distributions.  Write a helper function to train models on subsets of the data.

# COMMAND ----------

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error

def return_mse(df, distribution=None):
  if distribution:
    subset_df = df[df['distribution'] == distribution]
  else:
    subset_df = df.copy()
    
  trained_model = RandomForestRegressor(n_estimators=100, random_state=42).fit(subset_df['random-x'].values.reshape(-1, 1), subset_df['y'])
  mse = mean_squared_error(subset_df['y'], trained_model.predict(subset_df['random-x'].values.reshape(-1, 1)))
  return mse
  
return_mse(df)

# COMMAND ----------

# MAGIC %md
# MAGIC See how the different subsets compare.

# COMMAND ----------

print("MSE for model trained on all data: {}".format(return_mse(df)))
print("MSE for model trained on distribution 1: {}".format(return_mse(df, 1)))
print("MSE for model trained on distribution 2: {}".format(return_mse(df, 2)))
print("MSE for model trained on distribution 3: {}".format(return_mse(df, 3)))

# COMMAND ----------

# MAGIC %md
# MAGIC What is the optimal window to retrain the model?

# COMMAND ----------

# MAGIC %md
# MAGIC ### Detecting Drift
# MAGIC 
# MAGIC As we saw above, choosing the best window to retrain our model is difficult, and is often done somewhat randomly.  The best window depends on a number of issues, especially on how abrupt we expect the drift to be.
# MAGIC 
# MAGIC A more rigorous way of addressing drift is to first detect drift using statistical methods.  This could be as simple as monitoring model error.  The package <a href="https://scikit-multiflow.github.io/scikit-multiflow/skmultiflow.drift_detection.html#module-skmultiflow.drift_detection" target="_blank">`skmultiflow` has some good options for this.</a>

# COMMAND ----------

import skmultiflow.drift_detection as drift

adwin = drift.ADWIN(delta=.001)

for i in range(len(df)):
  adwin.add_element(df['y'][i])
  if adwin.detected_change():
    print("Change detected in data at index: {}".format(i))
    adwin.reset_change()

# COMMAND ----------

# MAGIC %md
# MAGIC Try the DDM method instead.

# COMMAND ----------

import numpy as np
from skmultiflow.drift_detection import DDM

ddm = DDM()

# Simulating a data stream as a normal distribution of 1's and 0's
data_stream = np.random.randint(2, size=2000)

# Changing the data concept from index 999 to 1500, simulating an
# increase in error rate
for i in range(999, 1500):
    data_stream[i] = 0

# Adding stream elements to DDM and verifying if drift occurred
for i in range(2000):
    ddm.add_element(data_stream[i])
    if ddm.detected_warning_zone():
       print("Warning zone detected at index {}".format(i))
    if ddm.detected_change():
       print("Change detected at index {}".format(i))
       ddm.reset()

# COMMAND ----------

# MAGIC %md
# MAGIC Finally, try the Page Hinkley algorithm.

# COMMAND ----------

import numpy as np
from skmultiflow.drift_detection import PageHinkley

ph = PageHinkley()

# Simulating a data stream as a normal distribution of 1's and 0's
data_stream = np.random.randint(2, size=2000)

# Changing the data concept from index 999 to 2000
for i in range(999, 2000):
  data_stream[i] = np.random.randint(4, high=8)
  
# Adding stream elements to the PageHinkley drift detector and verifying if drift occurred
for i in range(2000):
  ph.add_element(data_stream[i])
  if ph.detected_change():
    print('Change has been detected in data: ' + str(data_stream[i]) + ' - of index: ' + str(i))

# COMMAND ----------

# MAGIC %md
# MAGIC ## Review
# MAGIC 
# MAGIC **Question:** Why do some of the common assumptions of machine learning not apply to real world datasets?  
# MAGIC **Answer:** On large assumption in machine learning is the existance of static data created by a static distribution.  The reality is that data changes over time when the underlying mechanism of that change is not fully modeled.  Real world machine learning models have to be able to handle "concept drift" where the context in which the model was changed evolves over time.  This can pose many challenges, one being in recommender systems that want to recommend to different modalities of a user.  For instance, one of those modalities might be nostalgia, which would require the use of older data.
# MAGIC 
# MAGIC **Question:** What are the pros and cons of using a window or function that considers recent data more strongly?  
# MAGIC **Answer:** The main benefit of this approach is that it will adapt a model over time.  The downside is that it is difficult to know who to set the parameters of that window.  We know with statistical certainty that models perform better with more data when that data originates from the same probability distribution.  However, knowing when that context has changed is challenging so knowing what data to use when retraining a model is non-trivial.
# MAGIC 
# MAGIC **Question:** What is the best way of knowing when to retrain a model?  
# MAGIC **Answer:** The easiest solution is to set up an alerting mechanism for when a model's error begins to slip.  The naive implementation of this might look for a 10% slip in error before raising an alarm.  A more riogorous approach would look to quantify the shift in context.  These approaches often look at the confidence intervals for a given outcome such as the label.  When a threshold is reached, it is said that the data is originating from a new context.  These adaptive solutions are largely understudied, so academic research and newer libraries are the best place to source these solutions.

# COMMAND ----------

# MAGIC %md
# MAGIC ## Next Steps
# MAGIC 
# MAGIC Start the next lesson, [Alerting]($./10-Alerting ).

# COMMAND ----------

# MAGIC %md
# MAGIC ## Additional Topics & Resources
# MAGIC 
# MAGIC **Q:** What are libraries for handling drift?  
# MAGIC **A:** Check out <a href="https://moa.cms.waikato.ac.nz/" target="_blank">MOA</a> and <a href="https://scikit-multiflow.github.io/" target="_blank">scikit-multiflow</a>.
# MAGIC 
# MAGIC **Q:** What's a good general introduction to drift?  
# MAGIC **A:** Check out <a href="https://en.wikipedia.org/wiki/Concept_drift" target="_blank">the Wikipedia article on it.</a>
# MAGIC 
# MAGIC **Q:** What are good academic resources for drift?  
# MAGIC **A:** Check out the papers <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.108.1833&rep=rep1&type=pdf" target="_blank">Learning with Drift Detection</a>, <a href="https://www.win.tue.nl/~mpechen/publications/pubs/CD_applications15.pdf" target="_blank">An overview of concept drift applications</a>, and <a href="https://arxiv.org/pdf/1504.01044.pdf" target="_blank">Concept Drift Detection for Streaming Data</a>.
# MAGIC 
# MAGIC **Q:** How can I classify different types of drift?  
# MAGIC **A:** Check out the paper <a href="https://rtg.cis.upenn.edu/cis700-2019/papers/dataset-shift/dataset-shift-terminology.pdf" target="_blank">A unifying view on dataset shift in classification</a>.

# COMMAND ----------

# MAGIC %md-sandbox
# MAGIC &copy; 2019 Databricks, Inc. All rights reserved.<br/>
# MAGIC Apache, Apache Spark, Spark and the Spark logo are trademarks of the <a href="http://www.apache.org/">Apache Software Foundation</a>.<br/>
# MAGIC <br/>
# MAGIC <a href="https://databricks.com/privacy-policy">Privacy Policy</a> | <a href="https://databricks.com/terms-of-use">Terms of Use</a> | <a href="http://help.databricks.com/">Support</a>